{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the images for dogs\n",
    "Load libs\n",
    "https://www.kaggle.com/code/khushikhushikhushi/dog-breed-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import cv2\n",
    "import datetime\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function to load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, image_size=(150, 150)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        label_path = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for filename in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, filename)\n",
    "                img = Image.open(img_path)\n",
    "                img = img.resize(image_size)\n",
    "                img = np.array(img)\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/prasad/09_personal/Coding_N_Work/2_ML_NN/Computer_Vision_data_Explore/dataset_dogs'\n",
    "image_size = (150, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_images_from_folder(data_dir, image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize pixel values to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert labels to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (773, 150, 150, 3)\n",
      "X_val shape: (194, 150, 150, 3)\n",
      "y_train shape: (773, 10)\n",
      "y_val shape: (194, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'y_val shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 19:24:06.322048: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-06-29 19:24:06.322121: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (XDEM-laptop): /proc/driver/nvidia/version does not exist\n",
      "2024-06-29 19:24:06.323236: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# here we use a bit of bigger pooling to extract broader features\n",
    "model1 = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(3, 3),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(3, 3),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model1.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TensorBoard callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "25/25 [==============================] - ETA: 0s - loss: 2.2347 - accuracy: 0.2639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 19:24:55.988933: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4545576960 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 48s 2s/step - loss: 2.2347 - accuracy: 0.2639 - val_loss: 1.7641 - val_accuracy: 0.4639\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.2283 - accuracy: 0.6080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 19:25:49.891480: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4545576960 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# %timeit \n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start tesnorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Validation accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "# Save the model\n",
    "model.save('dog_breed_classifier_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict breed of a random dog from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random_image(model, X, y, label_encoder):\n",
    "    idx = random.randint(0, len(X) - 1)\n",
    "    plt.imshow(X[idx])\n",
    "    plt.title(f'Actual: {label_encoder.inverse_transform([np.argmax(y[idx])])[0]}')\n",
    "    plt.show()\n",
    "\n",
    "    # Predict the class of the selected image\n",
    "    y_pred = model.predict(X[idx].reshape(1, 150, 150, 3))\n",
    "    print(f'Prediction probabilities: {y_pred}')\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = label_encoder.inverse_transform([np.argmax(y_pred)])\n",
    "    print(f'Predicted class: {predicted_class[0]}')\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('dog_breed_classifier_model.h5')\n",
    "\n",
    "# Predict for a random image\n",
    "predict_random_image(model, X_val, y_val, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I test actual pictures of my dog and see if my model identifies it\n",
    "She is labrador btw ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/home/prasad/09_personal/Coding_N_Work/2_ML_NN/Computer_Vision_data_Explore/dataset_dogs/Test/'\n",
    "pred_dir = '/home/prasad/09_personal/Coding_N_Work/2_ML_NN/Computer_Vision_data_Explore/dataset_dogs/zzz_my_predictions/'\n",
    "\n",
    "# Check the input shape of the model\n",
    "input_shape = model.layers[0].input_shape\n",
    "img_height, img_width = input_shape[1], input_shape[2]\n",
    "target_image_size=(img_height, img_width)\n",
    "\n",
    "# Iterate through the images in the test directory and process them\n",
    "test_images = []\n",
    "for filename in os.listdir(test_dir):\n",
    "    img_path = os.path.join(test_dir, filename)\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(target_image_size)\n",
    "    img = np.array(img)\n",
    "    img = img / 255.0 # Normalize the image array\n",
    "    test_images.append(img)\n",
    "\n",
    "len(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for my dog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_my_test_image(model, X, label_encoder, idx, save_dir, training_images):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Predict the class of the selected image\n",
    "    y_pred = model.predict(X[idx].reshape(1, 150, 150, 3))\n",
    "    # print(f'Prediction probabilities: {y_pred}')\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = label_encoder.inverse_transform([np.argmax(y_pred)])\n",
    "    print(f'Predicted class: {predicted_class[0]}')\n",
    "\n",
    "    # idx = random.randint(0, len(X) - 1)\n",
    "    # plt.imshow(X[idx])\n",
    "    # plt.show()\n",
    "\n",
    "    # Convert numpy array to PIL image\n",
    "    img = Image.fromarray((X[idx] * 255).astype(np.uint8))\n",
    "    # Resize the image to the desired output size\n",
    "    output_size = (500,500)\n",
    "    img = img.resize(output_size, Image.ANTIALIAS)\n",
    "\n",
    "    # Draw the predicted class on the image\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    font_size = 30\n",
    "    font_path = os.path.join(cv2.__path__[0],'qt','fonts','DejaVuSans.ttf')\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    text = f'Predicted: {predicted_class[0]}'\n",
    "    textwidth, textheight = draw.textsize(text, font)\n",
    "    width, height = img.size\n",
    "    margin = 10\n",
    "    x = width - textwidth - margin\n",
    "    y = height - textheight - margin\n",
    "\n",
    "    draw.text((x, y), text, font=font, fill=(255, 255, 255, 255))\n",
    "\n",
    "    # # Find the best matching image from training dataset X\n",
    "    # best_match_idx = np.argmax(y_pred)\n",
    "    # best_match_img = Image.fromarray((training_images[best_match_idx] * 255).astype(np.uint8))\n",
    "    # best_match_img = best_match_img.resize(output_size, Image.ANTIALIAS)\n",
    "\n",
    "    # # Create a new image with the original and the best match side by side\n",
    "    # comparison_img = Image.new('RGB', (2 * output_size[0], output_size[1]))\n",
    "    # comparison_img.paste(img, (0, 0))\n",
    "    # comparison_img.paste(best_match_img, (output_size[0], 0))\n",
    "\n",
    "    # # Save the comparison image with prediction text\n",
    "    # save_path = os.path.join(save_dir, f'comparison_{idx}.png')\n",
    "    # comparison_img.save(save_path)\n",
    "    # print(f'Saved comparison image with prediction at {save_path}')\n",
    "\n",
    "    # Save the image with prediction text\n",
    "    save_path = os.path.join(save_dir, f'predicted_{idx}.png')\n",
    "    img.save(save_path)\n",
    "    print(f'Saved image with prediction at {save_path}')\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('dog_breed_classifier_model.h5')\n",
    "\n",
    "# Predict for a random image\n",
    "for img_id in range(len(test_images)):\n",
    "    predict_my_test_image(model, test_images, label_encoder, img_id, pred_dir, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and validation loss from history object\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Create an array of epochs\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.yscale('log') \n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot as a PNG file\n",
    "plt.savefig('training_validation_loss.png')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
